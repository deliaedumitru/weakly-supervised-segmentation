{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Unet model for segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_PATH = './dataset/tiles/images/'\n",
    "TILE_GT_PATH = './dataset/tiles/ground_truth/'\n",
    "LABELS_FILE = './dataset/tiles/labels.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "First we create a Dataset object and a transform function that converts a data point to a tensor. We load the tile dataset and then we split it randomly as follows: \n",
    "\n",
    "* 10% N1 train - pixel-level labels;\n",
    "* 70% N2 train - class labels;\n",
    "* 20% validation - validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaihingenDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, gt_dir, transform=None):\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.gt_dir = gt_dir\n",
    "\n",
    "        self.data_points = os.listdir(self.img_dir)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_name = os.path.join(self.img_dir,\n",
    "                                self.data_points[idx])\n",
    "        gt_name = os.path.join(self.gt_dir, self.data_points[idx])\n",
    "\n",
    "        img = io.imread(img_name) \n",
    "        gt = io.imread(gt_name)\n",
    "\n",
    "        sample = (img.astype(np.float32), gt.astype(np.float32))\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img, gt = sample[0], sample[1]\n",
    "\n",
    "        # swapping axes\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        gt = gt.transpose((2, 0, 1))\n",
    "        return (torch.from_numpy(img), torch.from_numpy(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = VaihingenDataset(TILE_PATH, TILE_GT_PATH, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N1 train size: 1463/14636.\n",
      "N2 train size: 10245/14636.\n",
      "Validation size: 2928/14636.\n"
     ]
    }
   ],
   "source": [
    "n1_len = int(0.1 * len(ds))\n",
    "n2_len = int(0.7 * len(ds))\n",
    "n_valid_len = len(ds) - n1_len - n2_len\n",
    "\n",
    "print('N1 train size: {}/{}.'.format(n1_len, len(ds)))\n",
    "print('N2 train size: {}/{}.'.format(n2_len, len(ds)))\n",
    "print('Validation size: {}/{}.'.format(n_valid_len, len(ds)))\n",
    "\n",
    "n1_train, n2_train, n_valid = random_split(ds, [n1_len, n2_len, n_valid_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a data loader for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1_dataloader = DataLoader(n1_train, batch_size=128)\n",
    "n2_dataloader = DataLoader(n2_train, batch_size=128)\n",
    "n_valid_dataloader = DataLoader(n_valid, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
